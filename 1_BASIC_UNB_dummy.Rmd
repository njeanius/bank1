---
title: "All 7 models - nb, C5.0, JRip, glm, kknn, nnet, svmlinear"
author: "jean wills"
date: "13/07/2020"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```

# step 1a - need to get to "BM_mini_sc" (added 95% CI + numeric scaled) 

```{r}
library(plyr)
library(dplyr)
BM_mini <- read.csv("/Users/jeanwills/Desktop/CKME136/1_data/bank.csv", header=T, sep = ";", stringsAsFactors = T, na.strings = "NA")
# Step 1 - NUMERIC DATA Cleaning - change numeric data outside the 2.5% and the 97.5% percentiles to this maximum/minimum value
BM<-BM_mini

# now have file BM ..
```

## step 1b - BM -> BM_dummy

## Part 3 - step 2b: Conversion B- Categorical to Numeric - as dummy variables - RESULT is "BM_dummy or BM_mini_dummy"

```{r}
# original numeric still NOT normalized/scaled
# dummy coding
# keep y as factor
BM_d <- BM
# BM_dummy <- BM
# now create new attributes for each component in attribute less 1 category
# for example, marital has 3 attributes so we need 2 dummy variables (each of 0,1)
# BM_fact$y<- ifelse(BM_fact$y==c("yes"), 0, 1)
#
BM_d$job1 <- ifelse(BM_d$job == c("admin."), 1, 0)
BM_d$job2 <- ifelse(BM_d$job == c("blue-collar"), 1, 0)
BM_d$job3 <- ifelse(BM_d$job == c("entrepreneur"), 1, 0)
BM_d$job4 <- ifelse(BM_d$job == c("housemaid"), 1, 0)
BM_d$job5 <- ifelse(BM_d$job == c("management"), 1, 0)
BM_d$job6 <- ifelse(BM_d$job == c("retired"), 1, 0)
BM_d$job7 <- ifelse(BM_d$job == c("self-employed"), 1, 0)
BM_d$job8 <- ifelse(BM_d$job == c("services"), 1, 0)
BM_d$job9 <- ifelse(BM_d$job == c("student"), 1, 0)
BM_d$job10 <- ifelse(BM_d$job == c("technician"), 1, 0)
BM_d$job11 <- ifelse(BM_d$job == c("unemployed"), 1, 0)
BM_d$job12 <- ifelse(BM_d$job == c("unknown"), 1, 0)
#
BM_d$mar1 <-  ifelse(BM_d$marital== c("divorced"), 1, 0)
BM_d$mar2 <-  ifelse(BM_d$marital== c("married"), 1, 0)
BM_d$mar3 <-  ifelse(BM_d$marital== c("single"), 1, 0)
#
BM_d$ed1 <- ifelse(BM_d$education == c("primary"), 1, 0)
BM_d$ed2 <- ifelse(BM_d$education == c("secondary"), 1, 0)
BM_d$ed3 <- ifelse(BM_d$education == c("tertiary"), 1, 0)
BM_d$ed4 <- ifelse(BM_d$education == c("unknown"), 1, 0)

#
BM_d$hous1 <- ifelse(BM_d$housing == c("no"), 1, 0)
BM_d$def1 <- ifelse(BM_d$default == c("no"), 1, 0)
BM_d$loan1 <- ifelse(BM_d$loan == c("no"), 1, 0)
#
BM_d$cont1 <- ifelse(BM_d$contact == c("cellular"), 1, 0)
BM_d$cont2 <- ifelse(BM_d$contact == c("telephone"), 1, 0)
BM_d$cont3 <- ifelse(BM_d$contact == c("unknown"), 1, 0)
#
BM_d$mon1 <- ifelse(BM_d$month == c("jan"), 1, 0)
BM_d$mon2 <- ifelse(BM_d$month == c("feb"), 1, 0)
BM_d$mon3 <- ifelse(BM_d$month == c("mar"), 1, 0)
BM_d$mon4 <- ifelse(BM_d$month == c("apr"), 1, 0)
BM_d$mon5 <- ifelse(BM_d$month == c("may"), 1, 0)
BM_d$mon6 <- ifelse(BM_d$month == c("jun"), 1, 0)
BM_d$mon7 <- ifelse(BM_d$month == c("jul"), 1, 0)
BM_d$mon8 <- ifelse(BM_d$month == c("aug"), 1, 0)
BM_d$mon9 <- ifelse(BM_d$month == c("sep"), 1, 0)
BM_d$mon10 <- ifelse(BM_d$month == c("oct"), 1, 0)
BM_d$mon11 <- ifelse(BM_d$month == c("nov"), 1, 0)
BM_d$mon12 <- ifelse(BM_d$month == c("dec"), 1, 0)
#
BM_d$pout1 <- ifelse(BM_d$poutcome == c("failure"), 1, 0)
BM_d$pout2 <- ifelse(BM_d$poutcome == c("success"), 1, 0)
BM_d$pout3 <- ifelse(BM_d$poutcome == c("other"), 1, 0)
BM_d$pout4 <- ifelse(BM_d$poutcome == c("unknown"), 1, 0)
# summary(BM_dummy)
# ok so we end up with a lot - then we have to delete the original Factor attributes
## now take out the original attributes and the answer Y column and RESULT: BM_dummy 
#
# keep the y column in separate file for now
BM_y<- BM_d[17]
# now take out y in file - to place later at the end
BM_d<- BM_d[-17]
# now take out the remaining factors one at a time
BM_d<- BM_d[-16]
BM_d<- BM_d[-11]
BM_d<- BM_d[-9]
BM_d<- BM_d[-8]
BM_d<- BM_d[-7]
BM_d<- BM_d[-5]
BM_d<- BM_d[-4]
BM_d<- BM_d[-3]
BM_d<- BM_d[-2]
# add back y at the end 
# y is still a factor
BM_d<- cbind(BM_d, BM_y)
# summary(BM_dummy)
# result: BM_dummy with dummies for categorical = > all numeric (still not scaled)
# convert
# BM_dummy<-BM_d
BM_mini_dm<-BM_d
rm(BM_d)
```


# step 2 - run training and test datasets FOR ALL CONFIGURATIONS

```{r}
# rename dataset here:
BM<- BM_mini_dm
set.seed(30)
# get train and test datasets
# note that if we use cross validation, we can use the complete dataset for training or keep a portion for validation after
#
BM_train_index <- sample(nrow(BM), 0.7 * nrow(BM))
BM_train<- BM[BM_train_index, ]
BM_test <- BM[-BM_train_index, ]
# BM_train_labels <- BM[BM_train_index, 17]
# BM_test_labels <- BM[-BM_train_index, 17]
# note that we only balance the training sets
# and leave test set as is.
```

# step 3a - run SPECIFIC Balancing step to get balanced data version:

## for unbalanced, rename the files to make it easy....chnage -17 to -49

```{r}
# summary(BM_mini_dm)
table(BM_train$y) 
x=BM_train[,-49]
trainsv=BM_train
train=BM_train
y=BM_train$y
test_noy=BM_test[,-49]
test_labels=BM_test$y
```

# step 4 - now run models

## MODEL 1 NAIVE BAYES - uses caret

```{r}
# FINAL PARAMETER VALUES USED WERE fL = 0, usekernel = TRUE and adjust = 1.
library(klaR)
library(caret)
library(e1071)
library(MASS)
set.seed(520)
nb_grid <- expand.grid(fL= 0, usekernel= c("TRUE"), adjust=1)
# nb_grid <- expand.grid(fL= c(0,1), usekernel= c("TRUE", "FALSE"), adjust=c(0,1,2,3))
nab_mod<- train(x=x, y=y, method="nb", metric="ROC", tuneGrid=nb_grid, trControl = trainControl(method="repeatedcv", number=10, repeats=10, classProbs=TRUE, summaryFunction = twoClassSummary))
# to see model results:
# nab_mod
# predict output using test set - even though we did 10x10 cv above, we are also using 'validation' set of 30% of the data:
nab_pred<- predict(nab_mod, test_noy)
s<-table(nab_pred, test_labels)
# Confusion matrix
print(confusionMatrix(s))
```

### we can now run 10-fold on test dataset:

```{r}
# copy in files you need and use test dataset only 
banking<-BM_test

# the other way is to run 10-fold on the test dataset and take the average of the (10 times) F1 measure 
folds<- createFolds(banking$y, k=10)
    # create a function to do 10 folds of the data and run the statistics...
    results <- lapply(folds, function(x) {
              test<- banking[x,]
              pred<- predict(nab_mod, test[-49])
              actual<- test$y
              # PPV = TP/(TP+FP)
              # pos<-posPredValue(table(pred, actual))
              # I actually want: NPV= TN/(TN+FN) for precision of minority class
              pr<-negPredValue(table(pred, actual))
              # pr<-precision(table(pred, actual ))
              # rec<- recall(table(pred, actual))
              # i actually want specificity for recall of minority class
              rec<- specificity(table(pred, actual))
              F1<- 2 * pr * rec /(pr + rec)
              return(F1)
              })
   #
    # print(results)
    value<-mean(unlist(results))
    print(value)
    # print the average of the 10 F1 results for test set
```

## model 2 - C5.0 Decision Tree algorithm 

strengths: numeric/nominal, easy interpretation
weaknesses: biased splits, overfitting

```{r}
# The final tuning parameters used for the original model were trials = 1, model = tree and winnow = FALSE.
# Trials = an integer specifying the number of boosting iterations. A value of one indicates that a single model is used.
# winnow: A logical: should predictor winnowing (i.e feature selection) be used.
library(caret)
set.seed(40)
# c5_grid <- expand.grid(trials=c(1,3,5), model = c("tree", "rules"), winnow = c(TRUE, FALSE))
c5_grid <- expand.grid(trials = 1, model = "tree", winnow = FALSE)
c5_ctrl<- trainControl(method="repeatedcv", number = 10, repeats=10, classProbs=TRUE, summaryFunction = twoClassSummary)
c5_mod<- train(x,y, method="C5.0", metric="ROC", tuneGrid=c5_grid, trControl = c5_ctrl, verbose=FALSE)
c_pred<- predict(c5_mod, test_noy)
# Testing the result output
s<-table(c_pred, test_labels)
# Confusion matrix
print(confusionMatrix(s))
```

### we can now run 10-fold on test dataset:

```{r}
# copy in files you need and use test dataset only 
banking<-BM_test

# the other way is to run 10-fold on the test dataset and take the average of the (10 times) F1 measure 
folds<- createFolds(banking$y, k=10)
    # create a function to do 10 folds of the data and run the statistics...
    results <- lapply(folds, function(x) {
              test<- banking[x,]
              pred<- predict(c5_mod, test[-49])
              actual<- test$y
              # PPV = TP/(TP+FP)
              # pos<-posPredValue(table(pred, actual))
              # I actually want: NPV= TN/(TN+FN) for precision of minority class
              pr<-negPredValue(table(pred, actual))
              # pr<-precision(table(pred, actual ))
              # rec<- recall(table(pred, actual))
              # i actually want specificity for recall of minority class
              rec<- specificity(table(pred, actual))
              F1<- 2 * pr * rec /(pr + rec)
              return(F1)
              })
   #
    # print(results)
    value<-mean(unlist(results))
    print(value)
    # print the average of the 10 F1 results for test set
```

### to see model results:

```{r}
#c5_mod
#c5_mod$finalModel
# another way to see the tree's decisions and best attributes:
summary(c5_mod)
# we see the decision trees and....
# ... and best attributes: see below at bottom....
```

##  model 3 - JRip (rule learner)

```{r}
# The final values used for the model were NumOpt = 10, NumFolds = 10 and MinWeights = 10.
library(caret)
library(RWeka)
set.seed(50)
# JR_grid <- expand.grid(NumOpt=c(1,3,5,10), NumFolds=c(1,3,5,10),MinWeights=c(1,3,5,10))
JR_grid <- expand.grid(NumOpt=10, NumFolds=10, MinWeights=10)
JR_ctrl<- trainControl(method="repeatedcv", number = 10, repeats = 10, classProbs=TRUE, summaryFunction = twoClassSummary)
JR_mod<- train(x, y, method="JRip", metric="ROC", tuneGrid=JR_grid, trControl = JR_ctrl)
JR_pred<- predict(JR_mod, test_noy)
s<-table(JR_pred, test_labels)
# Confusion matrix
print(confusionMatrix(s))
```

### we can now run 10-fold on test dataset:

```{r}
# copy in files you need and use test dataset only 
banking<-BM_test

# the other way is to run 10-fold on the test dataset and take the average of the (10 times) F1 measure 
folds<- createFolds(banking$y, k=10)
    # create a function to do 10 folds of the data and run the statistics...
    results <- lapply(folds, function(x) {
              test<- banking[x,]
              pred<- predict(JR_mod, test[-49])
              actual<- test$y
              # PPV = TP/(TP+FP)
              # pos<-posPredValue(table(pred, actual))
              # I actually want: NPV= TN/(TN+FN) for precision of minority class
              pr<-negPredValue(table(pred, actual))
              # pr<-precision(table(pred, actual ))
              # rec<- recall(table(pred, actual))
              # i actually want specificity for recall of minority class
              rec<- specificity(table(pred, actual))
              F1<- 2 * pr * rec /(pr + rec)
              return(F1)
              })
   #
    # print(results)
    value<-mean(unlist(results))
    print(value)
    # print the average of the 10 F1 results for test set
```

### JRip rules compiled...

```{r}
JR_mod$finalModel
# all for outcome yes
```

## model 4 - Logistic Regression 

```{r}
# no parameters
library(caret)
set.seed(520)
log_mod<- train(x, y, method="glm", metric="ROC", family=binomial(link="logit"), trControl = trainControl(method="repeatedcv", number=10, repeats=10, verboseIter=FALSE, classProbs = TRUE, summaryFunction = twoClassSummary))
log_pred<- predict(log_mod, test_noy)
s<-table(log_pred, test_labels)
# Confusion matrix
print(confusionMatrix(s))
```

### we can now run 10-fold on test dataset:

```{r}
# copy in files you need and use test dataset only 
banking<-BM_test

# the other way is to run 10-fold on the test dataset and take the average of the (10 times) F1 measure 
folds<- createFolds(banking$y, k=10)
    # create a function to do 10 folds of the data and run the statistics...
    results <- lapply(folds, function(x) {
              test<- banking[x,]
              pred<- predict(log_mod, test[-49])
              actual<- test$y
              # PPV = TP/(TP+FP)
              # pos<-posPredValue(table(pred, actual))
              # I actually want: NPV= TN/(TN+FN) for precision of minority class
              pr<-negPredValue(table(pred, actual))
              # pr<-precision(table(pred, actual ))
              # rec<- recall(table(pred, actual))
              # i actually want specificity for recall of minority class
              rec<- specificity(table(pred, actual))
              F1<- 2 * pr * rec /(pr + rec)
              return(F1)
              })
   #
    # print(results)
    value<-mean(unlist(results))
    print(value)
    # print the average of the 10 F1 results for test set
```

### model results

```{r}
# to see model results:
summary(log_mod)
```

### plot to see the most important attributes (those that "stand out" at far left or right)

```{r}
require(coefplot)
coefplot(log_mod)
# to reinterpret data properly
# invlogit<- function (x) {1/(1+exp(-x))}
# invlogit(log_mod$coefficients)
# results of plot: duration, campaign, balance, poutcomesuccess, some months, , some jobs
```

## Model #5 - K-Nearest Neighbours

```{r}
# The final values used for the model were kmax = 9, distance = 2 and kernel = optimal
library(caret)
library(lattice)
library(ggplot2)
knn_ctrl<- trainControl(method="repeatedcv", number = 10, repeats = 10, classProbs=TRUE, summaryFunction = twoClassSummary)
# knn_grid<-expand.grid(kmax=c(5,7,9,13), distance=c(1,2,4,6), kernel=c("rectangular","rank","optimal"))
knn_grid<-expand.grid(kmax=9, distance=2, kernel="optimal")
knn_mod<- train(x=x,y=y, method="kknn", metric="ROC", tuneGrid=knn_grid, trControl=knn_ctrl, verbose=FALSE)
knn_pred<- predict(knn_mod, test_noy)
# Testing the result output
s<-table( knn_pred, test_labels)
# Confusion matrix
print(confusionMatrix(s))
```

### we can now run 10-fold on test dataset:

```{r}
# copy in files you need and use test dataset only 
banking<-BM_test

# the other way is to run 10-fold on the test dataset and take the average of the (10 times) F1 measure 
folds<- createFolds(banking$y, k=10)
    # create a function to do 10 folds of the data and run the statistics...
    results <- lapply(folds, function(x) {
              test<- banking[x,]
              pred<- predict(knn_mod, test[-49])
              actual<- test$y
              # PPV = TP/(TP+FP)
              # pos<-posPredValue(table(pred, actual))
              # I actually want: NPV= TN/(TN+FN) for precision of minority class
              pr<-negPredValue(table(pred, actual))
              # pr<-precision(table(pred, actual ))
              # rec<- recall(table(pred, actual))
              # i actually want specificity for recall of minority class
              rec<- specificity(table(pred, actual))
              F1<- 2 * pr * rec /(pr + rec)
              return(F1)
              })
   #
    # print(results)
    value<-mean(unlist(results))
    print(value)
    # print the average of the 10 F1 results for test set
```

## NEURAL NET - model 6
 
Positive: can be used for classification or numeric prediction, makes few assumptions about the data (doesnt have to be normalized).
Negative: SLOW..can overfit, 'black box'.

```{r}
# #1: The final parameter values used for the model were size = 16 and decay = 0.1.
# Size is the number of units in hidden layer (nnet fit a single hidden layer neural network) and 
# decay is the regularization parameter to avoid over-fitting.
require(mlbench)
require(caret)
require (nnet)
nnctrl = trainControl(method="repeatedcv", number=10, repeats = 10, classProbs=TRUE, summaryFunction = twoClassSummary)
# initially, create a grid list to find best parameters:
# nn_grid = expand.grid(size=c(1,4,8,16),decay=c(0,0.1,0.2,0.3,0.4))
nn_grid = expand.grid(size=16, decay=0.1)
nn_mod <- train(x=x, y=y, method="nnet", metric="ROC", trControl=nnctrl, tuneGrid=nn_grid, trace=FALSE)
nn_pred<- predict(nn_mod, test_noy)
# Testing the result output
s<-table( nn_pred, test_labels)
# Confusion matrix
print(confusionMatrix(s))
```

### we can now run 10-fold on test dataset:

```{r}
# copy in files you need and use test dataset only 
banking<-BM_test

# the other way is to run 10-fold on the test dataset and take the average of the (10 times) F1 measure 
folds<- createFolds(banking$y, k=10)
    # create a function to do 10 folds of the data and run the statistics...
    results <- lapply(folds, function(x) {
              test<- banking[x,]
              pred<- predict(nn_mod, test[-49])
              actual<- test$y
              # PPV = TP/(TP+FP)
              # pos<-posPredValue(table(pred, actual))
              # I actually want: NPV= TN/(TN+FN) for precision of minority class
              pr<-negPredValue(table(pred, actual))
              # pr<-precision(table(pred, actual ))
              # rec<- recall(table(pred, actual))
              # i actually want specificity for recall of minority class
              rec<- specificity(table(pred, actual))
              F1<- 2 * pr * rec /(pr + rec)
              return(F1)
              })
   #
    # print(results)
    value<-mean(unlist(results))
    print(value)
    # print the average of the 10 F1 results for test set
```

## SVM model 7 - using caret package and linear kernel. 

### Another supervised learning model. A SVM can be imagined as a surface thatc reates a boundary between points of data plotted in an n-space representing examples and their feature values. SVM creates a flat boundary called a hyperplane, which divides the space into homogeneous partitions on either side. This way, SVM combines nearest neighbour instance-based learning with linear regression modeling.

negatives: need to test various parameters and kernels to get best solution, can be slow, 'black box".
positives: good for binary classification, classification/numeric prediction


```{r}
# Linear (vanilla) kernel function. 
# The final values used for the model were Cost = 1 for classification.
library(caret)
library(kernlab)
fitctrl<- trainControl(method="repeatedcv", number = 10, repeats = 10, classProbs=TRUE, summaryFunction = twoClassSummary)
grid<-expand.grid(C=1)
sv_m<- train(y~., data=trainsv, method="svmLinear", metric="ROC", trControl=fitctrl, tunegrid=grid, verbose=FALSE)
sp<- predict(sv_m, test_noy)
s<-table( sp, test_labels)
# Confusion matrix
print(confusionMatrix(s))
```

### we can now run 10-fold on test dataset:

```{r}
# copy in files you need and use test dataset only 
banking<-BM_test

# the other way is to run 10-fold on the test dataset and take the average of the (10 times) F1 measure 
folds<- createFolds(banking$y, k=10)
    # create a function to do 10 folds of the data and run the statistics...
    results <- lapply(folds, function(x) {
              test<- banking[x,]
              pred<- predict(sv_m, test[-49])
              actual<- test$y
              # PPV = TP/(TP+FP)
              # pos<-posPredValue(table(pred, actual))
              # I actually want: NPV= TN/(TN+FN) for precision of minority class
              pr<-negPredValue(table(pred, actual))
              # pr<-precision(table(pred, actual ))
              # rec<- recall(table(pred, actual))
              # i actually want specificity for recall of minority class
              rec<- specificity(table(pred, actual))
              F1<- 2 * pr * rec /(pr + rec)
              return(F1)
              })
   #
    # print(results)
    value<-mean(unlist(results))
    print(value)
    # print the average of the 10 F1 results for test set
```


### END
